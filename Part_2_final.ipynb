{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Part-2 for report.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SW37nqQyLORQ","colab_type":"code","outputId":"d96ae18c-54da-40f9-fcbd-197064327aa2","executionInfo":{"status":"ok","timestamp":1575856630377,"user_tz":300,"elapsed":13856,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install pytorch-pretrained-bert\n","!pip install transformers\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n","Installing collected packages: regex, pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.11.1\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n","\u001b[K     |████████████████████████████████| 368kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 58.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 63.3MB/s \n","\u001b[?25hRequirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=12950fb0fb78b427012c8735c63ad2db89ad136673d5d652335c41b6f9244b3e\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eUjKuhY_EI5T","colab_type":"code","outputId":"4c7bd272-0b48-4f3f-8d52-53b07a7415ff","executionInfo":{"status":"ok","timestamp":1575856637757,"user_tz":300,"elapsed":3966,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import numpy as np\n","import torch\n","from typing import List\n","import torch.nn as nn\n","from torch.nn import init\n","import torch.optim as optim\n","import math\n","import random\n","import os\n","import csv\n","import sys\n","import tqdm\n","from tqdm import tqdm, trange\n","from pathlib import Path \n","import time\n","from tqdm import tqdm\n","import json\n","from gensim.models import Word2Vec\n","import pandas as pd\n","from keras.preprocessing.sequence import pad_sequences\n","# from pytorch_pretrained_bert import BertModel, BertForMaskedLM, BertForMultipleChoice \n","from transformers import BertConfig, BertModel, BertForMaskedLM, BertForMultipleChoice\n","from transformers import PreTrainedTokenizer, BertTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from typing import List\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n","\n","# from tqdm import tqdm_notebook as tqdm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6LTAeNRsKIns","colab_type":"code","colab":{}},"source":["#!pip install pytorch-pretrained-bert"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AY7uH8TAbnN5","colab_type":"code","outputId":"93f775c0-d057-45eb-d7a9-09cc128a49bc","executionInfo":{"status":"ok","timestamp":1575856658247,"user_tz":300,"elapsed":8179,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7OyCZ_60bxU8","colab_type":"code","outputId":"6617de96-0e2c-4adf-b5fa-498b94d49cd5","executionInfo":{"status":"ok","timestamp":1575856663039,"user_tz":300,"elapsed":1238,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"K7krSMj6iL6o","colab_type":"code","outputId":"a0bd864f-ddf1-49d3-cde6-f6d52c8932d7","executionInfo":{"status":"ok","timestamp":1575856689567,"user_tz":300,"elapsed":15374,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":248}},"source":["# XXX: only one GPU on Colab and isn’t guaranteed\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=49c23d01c6a6ec81187d36b5e0c532efa2824e477332bacc454579df6f6e48bf\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 24.7 GB  | Proc size: 2.7 GB\n","GPU RAM Free: 15567MB | Used: 713MB | Util   4% | Total 16280MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oON38TnIiaFI","colab_type":"code","colab":{}},"source":["# !kill -9 -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vc2ZzFqO5aug","colab_type":"code","outputId":"78d98769-307a-4a58-d49c-abfeb3e15c44","executionInfo":{"status":"ok","timestamp":1575191342058,"user_tz":300,"elapsed":16477,"user":{"displayName":"Abhishek Sarkar","photoUrl":"","userId":"04556928578932398482"}},"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["#@title Default title text\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HpkBBSzn2Qai","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","# Task we are doing (ROCStory next sentence prediction)\n","processors = {\n","    \"ROCStory\": ROCStoryProcessor()\n","}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNkdA2w1xqSP","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_test_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dg11clvBwAah","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","class InputExample(object):\n","    \"\"\"A single training/test example for multiple choice\"\"\"\n","\n","    def __init__(self, example_id, contexts, endings, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            example_id: Unique id for the example.\n","            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n","            question: string. The untokenized text of the second sequence (question).\n","            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.example_id = example_id\n","        # self.question = question\n","        self.contexts = contexts\n","        self.endings = endings\n","        self.label = label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJzTEolouZ1t","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","class InputFeatures(object):\n","    def __init__(self,\n","                 example_id,\n","                 choices_features,\n","                 label\n","\n","    ):\n","        self.example_id = example_id\n","        self.choices_features = [\n","            {\n","                'input_ids': input_ids,\n","                'input_mask': input_mask,\n","                'segment_ids': segment_ids\n","            }\n","            for input_ids, input_mask, segment_ids in choices_features\n","        ]\n","        self.label = label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtxIcTrUafjm","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","def _create_examples(lines: List[List[str]]):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        # if type == \"train\" and lines[0][-1] != 'label':\n","        #     raise ValueError(\n","        #         \"For training, the input file must contain a label column.\"\n","        #     )\n","\n","        # for line in lines[1:]:\n","        #   print(line)\n","        # print(lines[4])\n","          \n","\n","        examples = [\n","            InputExample(\n","                example_id= line[0],\n","                # question=\"\",   #line[2],  # in the swag dataset, the\n","                # common beginning of each\n","                # choice is stored in \"sent2\".\n","                contexts = [line[1], line[2], line[3], line[4]],\n","                endings = [line[5], line[6]],   \n","                label= line[7]\n","            ) for line in lines[1:]  # we skip the line with the column names\n","        ]\n","\n","        return examples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rs0X3RA22QVk","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","class ROCStoryProcessor(DataProcessor):\n","    \"\"\"Processor for the SWAG data set.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        # logger.info(\"LOOKING AT {} train\".format(data_dir))\n","        return _create_examples(ROCStoryProcessor()._read_csv(data_dir))\n","        # return ._read_csv(data_dir)\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        # logger.info(\"LOOKING AT {} dev\".format(data_dir))\n","        return self._create_examples(self._read_csv(os.path.join(data_dir, \"val.csv\")), \"dev\")\n","\n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        # logger.info(\"LOOKING AT {} dev\".format(data_dir))\n","        raise ValueError(\n","            \"For swag testing, the input file does not contain a label column. It can not be tested in current code\"\n","            \"setting!\"\n","        )\n","        return self._create_examples(self._read_csv(os.path.join(data_dir, \"test.csv\")), \"test\")\n","    def get_labels(self,):\n","        \"\"\"See base class.\"\"\"\n","        return [\"1\", \"2\"]\n","\n","    def _read_csv(self, input_file):\n","        \n","        with open(input_file, 'r', encoding='utf-8') as f:\n","            reader = csv.reader(f)\n","            lines = []\n","            \n","            for line in reader:\n","                if sys.version_info[0] == 2:\n","                    line = list(unicode(cell, 'utf-8') for cell in line)\n","                lines.append(line)\n","            return lines\n","# obj = ROCStoryProcessor()\n","# obj.get_train_examples(path_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cA06EWZu2QfI","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","def load_and_cache_examples(data_dir, task, tokenizer, evaluate=False, test=False):\n","    # if args.local_rank not in [-1, 0]:\n","    #     torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n","\n","    processor = processors[task]\n","    max_seq_length = 128\n","    # Load data features from cache or dataset file\n","    # if evaluate:\n","    #     cached_mode = 'dev'\n","    # elif test:\n","    #     cached_mode = 'test'\n","    # else:\n","    #     cached_mode = 'train'\n","    # assert (evaluate == True and test == True) == False\n","    # cached_features_file = os.path.join(data_dir, 'cached_{}_{}_{}_{}'.format(\n","    #     cached_mode,\n","    #     list(filter(None, args.model_name_or_path.split('/'))).pop(),\n","    #     str(args.max_seq_length),\n","    #     str(task)))\n","    # if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","    #     logger.info(\"Loading features from cached file %s\", cached_features_file)\n","    #     features = torch.load(cached_features_file)\n","    \n","    # logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n","    label_list = processor.get_labels()\n","    if evaluate:\n","        examples = processor.get_dev_examples(data_dir)\n","    elif test:\n","        examples = processor.get_test_examples(data_dir)\n","    else:\n","        examples = processor.get_train_examples(data_dir)\n","    # logger.info(\"Training number: %s\", str(len(examples)))\n","    # print(examples)\n","    features = convert_examples_to_features(\n","        examples,\n","        label_list,\n","        max_seq_length,\n","        PreTrainedTokenizer,\n","        pad_on_left=bool(0),                 # pad on the left for xlnet\n","        pad_token_segment_id= 0\n","    )\n","        # if args.local_rank in [-1, 0]:\n","        #     logger.info(\"Saving features into cached file %s\", cached_features_file)\n","        #     torch.save(features, cached_features_file)\n","\n","    # if args.local_rank == 0:\n","    #     torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n","\n","    # Convert to Tensors and build dataset\n","    all_input_ids = torch.tensor(select_field(features, 'input_ids'), dtype=torch.long)\n","    all_input_mask = torch.tensor(select_field(features, 'input_mask'), dtype=torch.long)\n","    all_segment_ids = torch.tensor(select_field(features, 'segment_ids'), dtype=torch.long)\n","    all_label_ids = torch.tensor([f.label for f in features], dtype=torch.long)\n","\n","    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KCjxESI2Qht","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"opEcoOXFqpZu","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","def convert_examples_to_features(\n","    examples: List[InputExample],\n","    label_list: List[str],\n","    max_length: int,\n","    tokenizer = PreTrainedTokenizer,\n","    pad_token_segment_id=0,\n","    pad_on_left=False,\n","    pad_token=0,\n","    mask_padding_with_zero=True,\n",") -> List[InputFeatures]:\n","    \"\"\"\n","    Loads a data file into a list of `InputFeatures`\n","    \"\"\"\n","    \n","    label_map = {label : i for i, label in enumerate(label_list)}\n","\n","    features = []\n","    for (ex_index, example) in tqdm(enumerate(examples), desc=\"convert examples to features\"):\n","        # if ex_index % 10000 == 0:\n","            # logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n","        choices_features = []\n","        for ending_idx, (context, ending) in enumerate(zip(example.contexts, example.endings)):\n","            text_a = context\n","            # if example.question.find(\"_\") != -1:\n","            #     # this is for cloze question\n","            #     text_b = example.question.replace(\"_\", ending)\n","            # else:\n","            #     text_b = example.question + \" \" + ending\n","\n","            text_b = ending\n","            print(text_a)\n","            print(text_b)\n","            inputs = tokenizer.encode_plus(\n","                text_a,\n","                text_b,\n","                add_special_tokens=True,\n","                max_length=max_length,\n","            )\n","            # if 'num_truncated_tokens' in inputs and inputs['num_truncated_tokens'] > 0:\n","            #     logger.info('Attention! you are cropping tokens (swag task is ok). '\n","            #             'If you are training ARC and RACE and you are poping question + options,'\n","            #             'you need to try to use a bigger max seq length!')\n","\n","            \n","            input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n","\n","            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","            # tokens are attended to.\n","            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","            # Zero-pad up to the sequence length.\n","            padding_length = max_length - len(input_ids)\n","            if pad_on_left:\n","                input_ids = ([pad_token] * padding_length) + input_ids\n","                attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n","                token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n","            else:\n","                input_ids = input_ids + ([pad_token] * padding_length)\n","                attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n","                token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n","\n","            assert len(input_ids) == max_length\n","            assert len(attention_mask) == max_length\n","            assert len(token_type_ids) == max_length\n","            choices_features.append((input_ids, attention_mask, token_type_ids))\n","\n","\n","        label = label_map[example.label]\n","        print(choices_features)\n","\n","        if ex_index < 2:\n","            logger.info(\"*** Example ***\")\n","            logger.info(\"race_id: {}\".format(example.example_id))\n","            for choice_idx, (input_ids, attention_mask, token_type_ids) in enumerate(choices_features):\n","                logger.info(\"choice: {}\".format(choice_idx))\n","                logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n","                logger.info(\"attention_mask: {}\".format(' '.join(map(str, attention_mask))))\n","                logger.info(\"token_type_ids: {}\".format(' '.join(map(str, token_type_ids))))\n","                logger.info(\"label: {}\".format(label))\n","\n","        features.append(\n","            InputFeatures(\n","                example_id=example.example_id,\n","                choices_features=choices_features,\n","                label=label,\n","            )\n","        )\n","\n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_lPQFxeTJGs","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","unk = '<UNK>'\n","# Consult the PyTorch documentation for information on the functions used below:\n","# https://pytorch.org/docs/stable/torch.html\n","\n","class RNN(nn.Module):\n","\tdef __init__(self, input_dim, h1, h):\n","\t\tsuper(RNN, self).__init__()\n","\t\tself.input_dim = input_dim\n","\t\tself.h = h\n","\t\tself.h1 = h1\n","\t\t# self.rnn = nn.RNNCell(self.input_dim, self.h1)\n","\t\tself.rnn = nn.RNN(input_size=self.input_dim, hidden_size=self.h1, num_layers=1, nonlinearity = 'relu')\n","\t\tself.W1 = nn.Linear(self.h1, self.h)\n","\t\tself.W2 = nn.Linear(self.h, 5)\n","\t\n","\t\tself.activation = nn.ReLU()\t\t\n","\t\tself.softmax = nn.LogSoftmax()\n","\t\tself.loss = nn.NLLLoss()\n","\n","\tdef compute_Loss(self, predicted_vector, gold_label):\n","\t\treturn self.loss(predicted_vector, gold_label)\t\n","\t\n","\tdef init_hidden(self):\n","        # (num_layers, batch_size, n_neurons)\n","\t\t\th = torch.randn(1, 1, self.h1, requires_grad = True, dtype=torch.float)*0.01\n","\t\t\treturn (h.cuda())\n","\n","\tdef forward(self, input_matrix): \n","\t\tn_word = input_matrix.size(0)\n","\t\tn_embed = input_matrix.size(1)\n","\t\tinput_matrix = input_matrix.reshape(n_word, 1, n_embed)\n","\t\tself.hx = self.init_hidden()\n","\t  \n","\t\trnn_out, self.hx = self.rnn(input_matrix, self.hx)     # Explain the architecture.\n","\t\trnn_out = rnn_out.reshape(n_word, self.h1)\n","\t\tself.hx = self.hx.squeeze(0).squeeze(1)\t  \n","\t\th_out = self.hx\n","\t\tz1 = self.W1(h_out)\n","\t\tz3 = self.activation(z1)\n","\t\tz2 = self.W2(z3)\t\n","\t\tpredicted_vector = self.softmax(self.activation(z2))\t\t# is activation required ?\n","\t\treturn predicted_vector"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkIvRMuigfnN","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Default title text\n","class BERT(nn.Module):\n","  def __init__(self):\n","    super(BERT, self).__init__()\n","    # self.h = h\n","    self.bert = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n","    # self.W1 = nn.Linear(self.h, 2)\n","  \n","    # self.activation = nn.ReLU()\t\t\n","    # self.softmax = nn.LogSoftmax()\n","    self.loss = nn.NLLLoss()\n","\n","  def compute_Loss(self, predicted_vector, gold_label):\n","    return self.loss(predicted_vector, gold_label)\n","  \n","  def forward(self, story, att_mask, label):\n","    input_ids = story.unsqueeze(0)\n","    att_mask = att_mask.unsqueeze(0)\n","    label = label.unsqueeze(0)\n","    loss = self.bert(input_ids, token_type_ids=None, attention_mask=att_mask, labels = label)\n","    # cont_vect2, _ = self.bert(story2, token_type_ids=None, attention_mask=att_mask2)\n","\n","    return loss\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LA2viw6i6RLg","colab_type":"code","outputId":"83abda17-6a6c-43ec-a2d0-ae6b0a2f48d4","executionInfo":{"status":"ok","timestamp":1575856725301,"user_tz":300,"elapsed":1241,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["# Load all files into DataFrame(Pandas)\n","# path_train = '/content/drive/My Drive/p4_NLP/train.csv'\n","# path_val = '/content/drive/My Drive/p4_NLP/dev.csv'\n","# path_test = '/content/drive/My Drive/p4_NLP/test.csv'\n","path_train = 'train.csv'\n","path_val = 'dev.csv'\n","path_test = 'test.csv'\n","data_train = pd.read_csv(path_train)\n","data_val = pd.read_csv(path_val)\n","data_test =pd.read_csv(path_test)\n","data_test.head(2)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InputStoryid</th>\n","      <th>InputSentence1</th>\n","      <th>InputSentence2</th>\n","      <th>InputSentence3</th>\n","      <th>InputSentence4</th>\n","      <th>RandomFifthSentenceQuiz1</th>\n","      <th>RandomFifthSentenceQuiz2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b929f263-1dcd-4a0b-b267-5d5ff2fe65bb</td>\n","      <td>My friends all love to go to the club to dance.</td>\n","      <td>They think it's a lot of fun and always invite.</td>\n","      <td>I finally decided to tag along last Saturday.</td>\n","      <td>I danced terribly and broke a friend's toe.</td>\n","      <td>My friends decided to keep inviting me out as ...</td>\n","      <td>The next weekend, I was asked to please stay h...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7cbbc0af-bcce-4f56-871d-963f9bb6a99d</td>\n","      <td>I tried going to the park the other day.</td>\n","      <td>The weather seemed nice enough for a walk.</td>\n","      <td>Within minutes of getting there I started snee...</td>\n","      <td>My eyes were watery and it was hard to breathe.</td>\n","      <td>My allergies were too bad and I had to go back...</td>\n","      <td>It reminded me of how much I loved spring flow...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           InputStoryid  ...                           RandomFifthSentenceQuiz2\n","0  b929f263-1dcd-4a0b-b267-5d5ff2fe65bb  ...  The next weekend, I was asked to please stay h...\n","1  7cbbc0af-bcce-4f56-871d-963f9bb6a99d  ...  It reminded me of how much I loved spring flow...\n","\n","[2 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"EvomKWAxWCBb","colab_type":"code","colab":{}},"source":["# !unzip '/content/drive/My Drive/p4_NLP/glove.840B.300d.zip'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DswvGR0NL9EE","colab_type":"code","colab":{}},"source":["def fetch_data(data):\n","\ttoken_data = []\n","\tlabels = []\n","\n","\tfor item in data.iterrows():\n","\t\t\n","\t\t# story = '[CLS]' + ' ' + item[1][1] + ' ' + item[1][2] + ' ' + item[1][3] + ' ' + item[1][4]\n","\t\tstory = item[1][1] + ' ' + item[1][2] + ' ' + item[1][3] + ' ' + item[1][4]\n","\t\t\n","\t\t# # Manually adding CLS --> SEP --> SEP\n","\t\t# storyend1  = story + ' ' + item[1][5] + ' ' + '[SEP]'\n","\t\t# storyend2 = story + ' ' + item[1][6] + ' ' + '[SEP]'\n","\t\t\n","\t\t# Adding CLS --> SEP --> SEP \n","\t\tstoryend1  = story + 'SEP' + item[1][5] \n","\t\tstoryend2 = story + 'SEP' + item[1][6] \n","\t\t\n","\t\t# # Adding CLS --> SEP\n","\t\t# storyend1  = story + ' ' + item[1][5] \n","\t\t# storyend2 = story + ' ' + item[1][6]\n","\t\t\n","\t\t\n","\t\ttoken_data.append(storyend1)\n","\t\ttoken_data.append(storyend2)\n","\t\tlabels.append(item[1][7])      # corresponding to label\n","\t  \n","\treturn token_data, labels\n","\t"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJU8iz1Po4b3","colab_type":"code","colab":{}},"source":["def fetch_data_test(data):\n","    token_data = []\n","    ids = []\n","    labels = []\n","    for item in data.iterrows():\n","      story = item[1][1] + ' ' + item[1][2] + ' ' + item[1][3] + ' ' + item[1][4]\n","      storyend1  = story + 'SEP' + item[1][5] \n","      storyend2 = story + 'SEP' + item[1][6] \n","      token_data.append(storyend1)\n","      token_data.append(storyend2)\n","      ids.append(item[1][0])\n","      labels.append(1)\n","    \n","    return token_data, ids, labels\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPqT-5YC8MxO","colab_type":"code","colab":{}},"source":["from numpy import *\n","import math\n","import matplotlib.pyplot as plt\n","def plot_learning_curve(train_loss_list, val_acc_list, epoch):\n","  fig = plt.figure()\n","  epoch_axis = linspace(1, epoch, epoch)\n","  a, = plt.plot(epoch_axis,train_loss_list, 'r*-', label='Line 1')\n","  b, = plt.plot(epoch_axis,val_acc_list, 'b*-', label='Line 2')\n","  plt.legend([a, b], ['Training Loss', 'Validation Acc'], loc='best')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Performance Parameters')\n","  plt.title('Learning Curve')\n","  plt.show()\n","\n","# plot_learning_curve([1,2,3], [4,5,6], 3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pefBhGiAMA4v","colab_type":"code","outputId":"49c9c90f-61a6-480c-8bf1-67ac1f92c2af","executionInfo":{"status":"ok","timestamp":1575860663132,"user_tz":300,"elapsed":419817,"user":{"displayName":"sivaji gowtham","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCrvJeC3f8MZRam3tkXmI6Xm50fU17BqQBAp3a5ZA=s64","userId":"09227610564193230075"}},"colab":{"base_uri":"https://localhost:8080/","height":852}},"source":["def main():\n","     \n","     best_model_file_name = 'bestmodel_bert.pt'\n","     model_choice = 'bert-large-uncased'   # 'bert-large-cased'\n","     random.seed(1234)\n","     np.random.seed(1234)\n","     torch.manual_seed(1234)\n","     if device_name == '/device:GPU:0':\n","       torch.cuda.manual_seed_all(1234)\n","    \n","     print(\"Fetching data...\")\n","     train_data, train_labels = fetch_data(data_train)        # \n","     val_data, val_labels = fetch_data(data_val)              #\n","     test_data, ids, test_labels = fetch_data_test(data_test)\n","     print(\"Fetched and extracted data!\")\n","     tokenizer = BertTokenizer.from_pretrained(model_choice, do_lower_case=True)\n","    #  tokenizer = PreTrainedTokenizer()\n","     \n","     input_ids_train_data = []\n","     token_typ_ids_train_data = []\n","     input_ids_val_data = []\n","     token_typ_ids_val_data = []\n","     input_ids_test_data = []\n","     token_typ_ids_test_data = []\n","\n","    #-------------------------------------------------------\n","    # Training with CLS --> SEP ---> SEP\n","     for train in train_data:\n","       item_train = train.split('SEP')\n","       output_train = tokenizer.encode_plus(item_train[0], text_pair=item_train[1], add_special_tokens=True)\n","       input_ids_train_data.append(output_train['input_ids'])\n","       token_typ_ids_train_data.append(output_train['token_type_ids'])\n","          \n","     for val in val_data:\n","       item_val = val.split('SEP')\n","       output_val = tokenizer.encode_plus(item_val[0], text_pair=item_val[1], add_special_tokens=True)\n","       input_ids_val_data.append(output_val['input_ids'])\n","       token_typ_ids_val_data.append(output_val['token_type_ids'])\n","     \n","     for test in test_data:\n","       item_test = test.split('SEP')\n","       output_test = tokenizer.encode_plus(item_test[0], text_pair=item_test[1], add_special_tokens=True)\n","       input_ids_test_data.append(output_test['input_ids'])\n","       token_typ_ids_test_data.append(output_test['token_type_ids'])\n","    #-------------------------------------------------------\n","\n","    # # Training with CLS --> SEP\n","    #  for train in train_data:\n","    #    output_train = tokenizer.encode_plus(train, add_special_tokens=True)\n","    #    input_ids_train_data.append(output_train['input_ids'])\n","    #    token_typ_ids_train_data.append(output_train['token_type_ids'])\n","          \n","    #  for val in val_data:\n","    #    output_val = tokenizer.encode_plus(val, add_special_tokens=True)\n","    #    input_ids_val_data.append(output_val['input_ids'])\n","    #    token_typ_ids_val_data.append(output_val['token_type_ids'])\n","\n","        \n","    #  tokenized_train_data = [tokenizer.tokenize(sent) for sent in train_data]\n","    #  tokenized_val_data = [tokenizer.tokenize(sent) for sent in val_data]\n","    #  print(\"Tokenized Data!\")\n","     \n","     MAX_LEN = 80\n","     input_ids_train_data = pad_sequences(input_ids_train_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")    # imported from Keras Preprocessing\n","     input_ids_val_data = pad_sequences(input_ids_val_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")        # imported from Keras Preprocessing\n","     input_ids_test_data = pad_sequences(input_ids_test_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","     token_typ_ids_train_data = pad_sequences(token_typ_ids_train_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","     token_typ_ids_val_data = pad_sequences(token_typ_ids_val_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","     token_typ_ids_test_data = pad_sequences(token_typ_ids_test_data, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","     \n","     print(\"Input IDs and padding generated!\")\n","     att_mask_train_data = []\n","     att_mask_val_data = []\n","     att_mask_test_data = []\n","     for seq in input_ids_train_data:\n","          seq_mask = [float(i>0) for i in seq]\n","          att_mask_train_data.append(seq_mask)\n","     for seq in input_ids_val_data:\n","          seq_mask = [float(i>0) for i in seq]\n","          att_mask_val_data.append(seq_mask)   \n","     for seq in input_ids_test_data:\n","          seq_mask = [float(i>0) for i in seq]\n","          att_mask_test_data.append(seq_mask)   \n","     print(\"Attention Masks generated!\")  \n","    \n","     print(\"Total training documents #:\", int(len(input_ids_train_data)/2))\n","     print(\"Total Validation documents #:\", int(len(att_mask_val_data)/2))\n","     print(\"Total Test documents #:\", int(len(att_mask_test_data)/2))\n","     print(\"Max sequence Length after padding:\", len(input_ids_train_data[0]))\n","\n","     n_train = int(len(input_ids_train_data)/2)\n","     n_val = int(len(att_mask_val_data)/2)\n","     n_test = int(len(att_mask_test_data)/2)\n","     n_seq_pad = len(input_ids_train_data[0])\n","  \n","     input_ids_train_data = torch.tensor(input_ids_train_data).long()\n","     input_ids_val_data = torch.tensor(input_ids_val_data).long()\n","     input_ids_test_data = torch.tensor(input_ids_test_data).long()\n","     att_mask_train_data = torch.tensor(att_mask_train_data).long()\n","     att_mask_val_data = torch.tensor(att_mask_val_data).long()\n","     att_mask_test_data = torch.tensor(att_mask_test_data).long()\n","     token_typ_ids_train_data = torch.tensor(token_typ_ids_train_data).long()\n","     token_typ_ids_val_data = torch.tensor(token_typ_ids_val_data).long()\n","     token_typ_ids_test_data = torch.tensor(token_typ_ids_test_data).long()\n","     train_labels = torch.tensor(train_labels) - 1\n","     val_labels = torch.tensor(val_labels) - 1\n","     test_labels = torch.tensor(test_labels)\n","     \n","     \n","     input_ids_train_data = input_ids_train_data.reshape(n_train, 2, n_seq_pad)\n","     input_ids_val_data = input_ids_val_data.reshape(n_val, 2, n_seq_pad)\n","     input_ids_test_data = input_ids_test_data.reshape(n_test, 2, n_seq_pad)\n","     att_mask_train_data = att_mask_train_data.reshape(n_train, 2, n_seq_pad)\n","     att_mask_val_data = att_mask_val_data.reshape(n_val, 2, n_seq_pad)\n","     att_mask_test_data = att_mask_test_data.reshape(n_test, 2, n_seq_pad)\n","     token_typ_ids_train_data = token_typ_ids_train_data.reshape(n_train, 2, n_seq_pad)\n","     token_typ_ids_val_data = token_typ_ids_val_data.reshape(n_val, 2, n_seq_pad)\n","     token_typ_ids_test_data = token_typ_ids_test_data.reshape(n_test, 2, n_seq_pad)\n","           \n","     #  config = BertConfig.from_pretrained('bert-base-uncased', num_labels=2)\n","     model = BertForMultipleChoice.from_pretrained(model_choice)\n","     model.cuda()\n","     for p in model.parameters():\n","         p.requires_grad = True\n","    \n","    # # -------------------------------------------------------------------------------\n","    # # TEST PHASE (SUCCESS!) # NEED TO IMPLEMENT FANCY SCHEDULING!\n","    # #  a = model(input_ids_train_data[0], att_mask_train_data[0], train_labels[0])\n","    # #  print(a)\n","    # #  predicted_vector = a[1].squeeze(0)\n","    # #  print(predicted_vector.view(1,-1))\n","    # #  print(train_labels[0].unsqueeze(0))\n","    # #  loss = model.compute_Loss(predicted_vector.view(1,-1), train_labels[0].unsqueeze(0))\n","    # #  print(loss)\n","    # # -------------------------------------------------------------------------------\n","    \n","     # Inputing the data into DataLoader for training and Validation\n","     batch_size = 8\n","     train_set = TensorDataset(input_ids_train_data, att_mask_train_data, token_typ_ids_train_data, train_labels)\n","     train_sampler = RandomSampler(train_set)\n","     val_set = TensorDataset(input_ids_val_data, att_mask_val_data ,token_typ_ids_val_data, val_labels)\n","     val_sampler = SequentialSampler(val_set)\n","     test_set = TensorDataset(input_ids_test_data, att_mask_test_data ,token_typ_ids_test_data, test_labels)\n","     train_loader = DataLoader(train_set, batch_size = batch_size, sampler = train_sampler)\n","     val_loader =  DataLoader(val_set, batch_size = batch_size, shuffle = False)\n","     test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False)\n","\n","     # Prepare optimizer and schedule (linear warmup and decay)\n","     no_decay = ['bias', 'LayerNorm.weight']\n","     n_epoch = 3\n","     learning_rate = 5e-5\n","     adam_epsilon = 1e-8\n","     warmup_steps = 4\n","     t_total = len(train_loader) // batch_size * n_epoch\n","     weight_decay = 0.0\n","     optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","     optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n","     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n","     \n","     \n","    #  torch.cuda.empty_cache()\n","     best_val_acc = 0\n","     train_loss_list = []\n","     val_acc_list = []\n","     for epoch in tqdm(range(n_epoch), position=0, leave=False):\n","       model.train()\n","       loss = None\n","       correct = 0\n","       total = 0\n","       loss_epoch = 0\n","       start_time = time.time()\n","       for step, batch in enumerate(train_loader):\n","         optimizer.zero_grad()\n","         loss = None\n","         batch = tuple(t.to(device) for t in batch)\n","         input_ids, att_mask, token_id_typ, label = batch\n","         loss_batch, pred_vector = model(input_ids,  token_type_ids=token_id_typ, attention_mask=att_mask, labels = label)\n","         pred_label = torch.argmax(pred_vector, axis=1)\n","         correct += torch.sum(pred_label == label).item()\n","         total += input_ids.size(0)  \n","         loss = loss_batch\n","         loss_epoch += loss_batch.item()\n","         loss.backward()\n","         optimizer.step()\n","         scheduler.step()\n","\n","       train_loss_list.append(loss_epoch) \n","      #  print(train_loss_list)   \n","       print(\"\\nTraining completed for epoch {}\".format(epoch + 1))\n","       print(\"Training accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n","       print(\"Training time for this epoch: {}\".format(time.time() - start_time))\n","       print(\"Total number of training examples: {}\".format(total))\n","       print(\"Number of correctly predicted examples: {}\".format(correct))\n","\n","       with torch.no_grad():\n","         model.eval()\n","         loss_val = None\n","         correct = 0\n","         total = 0\n","         total_pred_label = torch.tensor([0]).cuda()\n","         start_time = time.time()\n","         for step, batch in enumerate(val_loader):\n","           \n","           batch = tuple(t.to(device) for t in batch)\n","           input_ids, att_mask, token_id_typ, label = batch\n","           loss_batch, pred_vector = model(input_ids,  token_type_ids=token_id_typ, attention_mask=att_mask, labels = label)\n","           pred_label = torch.argmax(pred_vector, axis=1)\n","           total_pred_label = torch.cat((total_pred_label, (pred_label+1)), axis=0)\n","           correct += torch.sum(pred_label == label).item()\n","           total += input_ids.size(0)\n","           loss_val = loss_batch\n","         \n","         total_pred_label = total_pred_label[1:]\n","         total_pred_label = total_pred_label.detach().cpu().numpy()\n","         total_pred_label = total_pred_label.tolist()\n","         output = pd.DataFrame({'Prediction': total_pred_label})\n","         path = 'val_part_b.csv'\n","         output.to_csv(path, index = False)\n","         output.head(5)\n","          \n","         print(\"\\nTraining completed for epoch {}\".format(epoch + 1))\n","         print(\"Validation accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n","         print(\"Validation time for this epoch: {}\".format(time.time() - start_time))\n","         print(\"Total number of Validation examples: {}\".format(total))\n","         print(\"Number of correctly predicted examples: {}\".format(correct)) \n","\n","         epoch_val_acc = correct / total\n","         val_acc_list.append(epoch_val_acc)\n","         if epoch_val_acc > best_val_acc:\n","           torch.save(model.state_dict(), best_model_file_name)\n","           best_val_acc = epoch_val_acc\n","\n","\n","     model.load_state_dict(torch.load(best_model_file_name))\n","     model.optimizer = optimizer\n","\n","          \n","     # Plot the performance curve for the model\n","     plot_learning_curve(train_loss_list, val_acc_list, n_epoch)  \n","     \n","     start_time = time.time()\n","     total_pred_label = torch.tensor([0]).cuda()\n","     for step, batch in enumerate(test_loader):\n","       batch = tuple(t.to(device) for t in batch)\n","       input_ids, att_mask, token_id_typ, label = batch\n","       _, pred_vector = model(input_ids,  token_type_ids=token_id_typ, attention_mask=att_mask, labels = label)\n","       pred_label = torch.argmax(pred_vector, axis=1)\n","       pred_label = pred_label + 1\n","       total_pred_label = torch.cat((total_pred_label, pred_label), axis=0)\n","     \n","     total_pred_label = total_pred_label[1:]\n","     total_pred_label = total_pred_label.detach().cpu().numpy()\n","     total_pred_label = total_pred_label.tolist()\n","\n","     output = pd.DataFrame({'Id': ids,\n","                            'Prediction': total_pred_label})\n","     output.set_index('Id')\n","     path = 'result_partB.csv'\n","     output.to_csv(path, index = False)\n","     output.head(5)\n","    \n","main()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fetching data...\n","Fetched and extracted data!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 424356.99B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Input IDs and padding generated!\n","Attention Masks generated!\n","Total training documents #: 1497\n","Total Validation documents #: 374\n","Total Test documents #: 1871\n","Max sequence Length after padding: 80\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 314/314 [00:00<00:00, 109250.22B/s]\n","100%|██████████| 1344997306/1344997306 [01:44<00:00, 12836850.20B/s]\n","  0%|          | 0/3 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Training completed for epoch 1\n","Training accuracy for epoch 1: 0.8076152304609219\n","Training time for this epoch: 88.16158294677734\n","Total number of training examples: 1497\n","Number of correctly predicted examples: 1209\n","\n","Training completed for epoch 1\n","Validation accuracy for epoch 1: 0.9144385026737968\n","Validation time for this epoch: 6.465898275375366\n","Total number of Validation examples: 374\n","Number of correctly predicted examples: 342\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|███▎      | 1/3 [01:38<03:16, 98.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Training completed for epoch 2\n","Training accuracy for epoch 2: 0.897127588510354\n","Training time for this epoch: 88.14215731620789\n","Total number of training examples: 1497\n","Number of correctly predicted examples: 1343\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|██████▋   | 2/3 [03:13<01:37, 97.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Training completed for epoch 2\n","Validation accuracy for epoch 2: 0.9144385026737968\n","Validation time for this epoch: 6.464851379394531\n","Total number of Validation examples: 374\n","Number of correctly predicted examples: 342\n","\n","Training completed for epoch 3\n","Training accuracy for epoch 3: 0.8931195724782899\n","Training time for this epoch: 88.10033535957336\n","Total number of training examples: 1497\n","Number of correctly predicted examples: 1337\n"],"name":"stdout"},{"output_type":"stream","text":["                                             "],"name":"stderr"},{"output_type":"stream","text":["\n","Training completed for epoch 3\n","Validation accuracy for epoch 3: 0.9144385026737968\n","Validation time for this epoch: 6.465304136276245\n","Total number of Validation examples: 374\n","Number of correctly predicted examples: 342\n"],"name":"stdout"},{"output_type":"stream","text":["\r"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4jXG7efxMa31","colab_type":"text"},"source":["### _2.csv is giving better results."]},{"cell_type":"markdown","metadata":{"id":"souoQSETGkgz","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Bdxsco4-Ph1Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}